{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a40f82bb-1e94-4e34-995c-0e0eb7fea638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "52c555b3-13fb-471a-b411-38917a87c2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_star_rating</th>\n",
       "      <th>product_num_offers</th>\n",
       "      <th>product_minimum_offer_price</th>\n",
       "      <th>is_prime</th>\n",
       "      <th>product</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>has_storage</th>\n",
       "      <th>brand</th>\n",
       "      <th>log_product_num_ratings</th>\n",
       "      <th>log_storage_capacity</th>\n",
       "      <th>product_x_brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.3</td>\n",
       "      <td>20</td>\n",
       "      <td>72.90</td>\n",
       "      <td>False</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0.111123</td>\n",
       "      <td>1</td>\n",
       "      <td>HONOR</td>\n",
       "      <td>6.948897</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>Phone_x_HONOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>129.99</td>\n",
       "      <td>False</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0.235308</td>\n",
       "      <td>1</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>8.368693</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>Phone_x_Samsung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.3</td>\n",
       "      <td>6</td>\n",
       "      <td>71.99</td>\n",
       "      <td>False</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0.078223</td>\n",
       "      <td>1</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>4.564348</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>Phone_x_Samsung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.5</td>\n",
       "      <td>18</td>\n",
       "      <td>143.10</td>\n",
       "      <td>False</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0.493762</td>\n",
       "      <td>1</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>5.826000</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>Phone_x_Samsung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5</td>\n",
       "      <td>19</td>\n",
       "      <td>125.00</td>\n",
       "      <td>False</td>\n",
       "      <td>Phone</td>\n",
       "      <td>0.079150</td>\n",
       "      <td>1</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>7.646831</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>Phone_x_Samsung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_star_rating  product_num_offers  product_minimum_offer_price  \\\n",
       "0                  4.3                  20                        72.90   \n",
       "1                  4.5                   1                       129.99   \n",
       "2                  4.3                   6                        71.99   \n",
       "3                  4.5                  18                       143.10   \n",
       "4                  4.5                  19                       125.00   \n",
       "\n",
       "   is_prime product  discount_rate  has_storage    brand  \\\n",
       "0     False   Phone       0.111123            1    HONOR   \n",
       "1     False   Phone       0.235308            1  Samsung   \n",
       "2     False   Phone       0.078223            1  Samsung   \n",
       "3     False   Phone       0.493762            1  Samsung   \n",
       "4     False   Phone       0.079150            1  Samsung   \n",
       "\n",
       "   log_product_num_ratings  log_storage_capacity  product_x_brand  \n",
       "0                 6.948897              4.859812    Phone_x_HONOR  \n",
       "1                 8.368693              4.859812  Phone_x_Samsung  \n",
       "2                 4.564348              4.174387  Phone_x_Samsung  \n",
       "3                 5.826000              4.859812  Phone_x_Samsung  \n",
       "4                 7.646831              4.859812  Phone_x_Samsung  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the preprocessed data into a dataframe\n",
    "data_path = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_path, 'amazon_data_clean.csv'))\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e52d4b2-f208-4297-9739-e6225c1141d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_star_rating            float64\n",
       "product_num_offers               int64\n",
       "product_minimum_offer_price    float64\n",
       "is_prime                          bool\n",
       "product                         object\n",
       "discount_rate                  float64\n",
       "has_storage                      int64\n",
       "brand                           object\n",
       "log_product_num_ratings        float64\n",
       "log_storage_capacity           float64\n",
       "product_x_brand                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e64c3360-a51b-4593-97ee-075e48f31a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the boolean variable: 'is_prime' \n",
    "df['is_prime'] = np.where(df['is_prime'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "beb210cb-7656-4162-aa37-9b9499113f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom class that imputes the 'product_star_rating' using the median, grouped by the Product Type\n",
    "class GroupedMedianImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, grouped, target):\n",
    "        self.grouped = grouped\n",
    "        self.target = target\n",
    "\n",
    "    def fit(self, X,y=None):\n",
    "        self.median_ = X.groupby(self.grouped)[self.target].median()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for product, median in self.median_.items():\n",
    "            # Impute missing values with the median when grouped by product\n",
    "            X.loc[X[self.grouped] == product, self.target] = X.loc[X[self.grouped] == product, self.target].fillna(median)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "45c226ce-5bdd-4f1d-b2f6-98326c1462bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for model training by creating a train/test split\n",
    "# Apply a log transformation to the target variable 'product_minimum_offer_price' to stabilise variance and reduce skewness.\n",
    "# 'has_storage' and 'is_prime' features are dropped due to their low feature importance after model evaluation. \n",
    "X = df.drop(['product_minimum_offer_price', 'has_storage', 'is_prime'], axis=1)\n",
    "y = np.log1p(df['product_minimum_offer_price'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c480a95c-3250-462a-8549-a491b4ef0589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 75 folds for each of 20 candidates, totalling 1500 fits\n",
      "Best R2 score: 0.7280601211493469\n",
      "Best Root Mean Squared Error (Log-scale): {0.6566183134052632}\n",
      "Best Params: {'model__n_estimators': 450, 'model__min_samples_split': 4, 'model__min_samples_leaf': 3, 'model__max_features': 'log2', 'model__max_depth': 13}\n"
     ]
    }
   ],
   "source": [
    "# Features to be processed\n",
    "numerical_features = ['product_star_rating', 'log_product_num_ratings', 'product_num_offers', 'log_storage_capacity']\n",
    "categorical_features = ['brand', 'product', 'product_x_brand']\n",
    "\n",
    "# Apply the imputer to the product star rating\n",
    "grouped_median_imputer = Pipeline(steps=[('imputer', GroupedMedianImputer('product', 'product_star_rating'))])\n",
    "\n",
    "# Preprocess categorical and numerical features\n",
    "preprocessor = ColumnTransformer(transformers=[('scaler', StandardScaler(), numerical_features),\n",
    "                                               ('encoder', TargetEncoder(target_type='continuous', cv=20), categorical_features)], remainder='passthrough')\n",
    "           \n",
    "            \n",
    "# Construct the pipeline\n",
    "pipeline = Pipeline(steps=[('grouped_median_imputer', grouped_median_imputer),\n",
    "                           ('preprocessor', preprocessor),\n",
    "                           ('model', RandomForestRegressor(random_state = 42))])\n",
    "\n",
    "# Parameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'model__n_estimators': [450, 455, 460],  \n",
    "    'model__max_depth': [10,13, 15],  \n",
    "    'model__min_samples_split': [4, 5], \n",
    "    'model__min_samples_leaf': [3, 4], \n",
    "    'model__max_features': ['log2'], \n",
    "}\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=15, random_state=42)\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=20,\n",
    "                                   cv=cv, scoring='r2', n_jobs=-1, verbose=1)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "print(\"Best R2 score:\", r2_score(y_test, y_pred))\n",
    "print(\"Best Root Mean Squared Error (Log-scale):\", {np.sqrt(mean_squared_error(y_test, y_pred))})\n",
    "print(\"Best Params:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "002315a8-9100-42ca-94d5-f0b585b0db2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scaler__log_storage_capacity</td>\n",
       "      <td>0.236765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>encoder__product</td>\n",
       "      <td>0.225644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>encoder__product_x_brand</td>\n",
       "      <td>0.205903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scaler__log_product_num_ratings</td>\n",
       "      <td>0.134592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encoder__brand</td>\n",
       "      <td>0.100413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scaler__product_star_rating</td>\n",
       "      <td>0.040645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scaler__product_num_offers</td>\n",
       "      <td>0.030621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>remainder__discount_rate</td>\n",
       "      <td>0.025417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Feature  Importance\n",
       "3     scaler__log_storage_capacity    0.236765\n",
       "5                 encoder__product    0.225644\n",
       "6         encoder__product_x_brand    0.205903\n",
       "1  scaler__log_product_num_ratings    0.134592\n",
       "4                   encoder__brand    0.100413\n",
       "0      scaler__product_star_rating    0.040645\n",
       "2       scaler__product_num_offers    0.030621\n",
       "7         remainder__discount_rate    0.025417"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate feature importance to guide the feature engineering process\n",
    "optimal_model = random_search.best_estimator_\n",
    "rfr = optimal_model.named_steps['model']\n",
    "feature_importance = rfr.feature_importances_\n",
    "preprocessor = optimal_model.named_steps['preprocessor']\n",
    "\n",
    "feature_importance = pd.DataFrame({'Feature': preprocessor.get_feature_names_out(), 'Importance': feature_importance})\n",
    "\n",
    "feature_importance.sort_values(by='Importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8f77bd27-609b-4677-ad55-34376d4e5d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.6899218831925331\n",
      "Log-scale RMSE: 0.7011518758428291\n"
     ]
    }
   ],
   "source": [
    "# Explore alternative models\n",
    "# Features to be processed\n",
    "cat_pipeline = Pipeline(steps=[('grouped_median_imputer', grouped_median_imputer),\n",
    "                           ('preprocessor', preprocessor), \n",
    "                           ('model', CatBoostRegressor(iterations = 8000, learning_rate=0.15, depth = 10, random_state=42, verbose=0))])\n",
    "\n",
    "\n",
    "cat_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = cat_pipeline.predict(X_test)\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred)}\")\n",
    "print(f\"Log-scale RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285cccaf-4969-4b02-8e0d-ffb14b4e28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the top performing model - Random Forest Regressor\n",
    "model_path = os.path.join(os.path.dirname(os.getcwd()), 'models')\n",
    "\n",
    "with open(os.path.join(model_path,'amazon_product_price_regressor.pkl'), 'wb') as f:\n",
    "    pickle.dump(optimal_model, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f0d4e4-7e98-4e71-913b-2b0686758d30",
   "metadata": {},
   "source": [
    "# Model Building and Evaluation Summary\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "- **Outliers Removal**: Removed outliers for the `storage_capacity` feature.\n",
    "- **Log Transformation**: Applied a log transformation to heavily right-skewed numerical features, including `product_num_ratings` and `storage_capacity`.\n",
    "- **Interaction Feature**: Created an interaction feature between `product` and `brand`, leveraging their high feature importance.\n",
    "- **Threshold-based Filtering**: Dropped any records where the count of `brand` was less than 10.\n",
    "\n",
    "## Model Building\n",
    "\n",
    "- **Log Transformation on Target Variable**: Applied a log transformation to the target variable (`product_minimum_offer_price`) before fitting the model, given how right-skewed the distribution was. The model performed better after applying the transformation.\n",
    "- **Feature Importance Evaluation**: Evaluated feature importance and dropped `has_storage` and `is_prime`, as these features demonstrated very minimal impact on the model's performance.\n",
    "- **Missing Data Imputation**: Created a custom column transformer to impute missing `product_star_rating` values. Imputed missing values with the median, grouped by product type, to address variations across different product categories.\n",
    "- **Categorical Encoding**: Used TargetEncoder for categorical features, which replaced each distinct category with the mean of the target variable for that category, outperforming the standard OneHotEncoding.\n",
    "- **Feature Scaling**: Applied StandardScaler to scale numerical features.\n",
    "- **Model Training and Hyperparameter Tuning**: Trained a Random Forest Regressor model, experimenting with various hyperparameters using **RandomizedSearchCV** to find the model with the best $R^2$ score.\n",
    "- **Model Comparison**: Trained a CatBoost Regressor, which yielded a comparable $R^2$ score of 0.69 (log-scale RMSE = 0.70). However, the Random Forest Regressor outperformed and responded better to hyperparameter tuning and feature engineering.\n",
    "\n",
    "## Performance Improvement\n",
    "\n",
    "- **Pre-feature engineering/hyperparameter tuning $R^2$**: 0.564\n",
    "- **Post-feature engineering/hyperparameter tuning $R^2$**: 0.73\n",
    "\n",
    "The model now explains 72% of the variance in the target variable, demonstrating a significant improvement in its ability to predict the product minimum offer price.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- To further improve the model, more data across all product types would be beneficial to help the model generalise better. Additional features could also be explored to better understand nuanced differences in pricing strategies between products.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
